### Welcome to Algorhythmic's GitHub page!

This project was built as part of Spiced Academy Berlin's: Data Science Bootcamp.

Shout out to [Johan Leduc](https://github.com/Joooohan/audio-recorder-streamlit) and his super lightweight, pip installable package for recording audio on Streamlit!

For a deep explanation on what types of data the models were trained on, see the [What is Sound](https://algorhythmic.streamlit.app/What_is_Sound). In brief, detailed audio features were pulled from Spotify's API, cleaned, organized, condensed, and lastly run through two separate models to attempt a method of genre classification using only audio input.

My main problem in this project was the inconsistent way the humans group music. Genres are varied and each person may say that a song belongs to one category or another. I think we could use computers to make meaningful insights in how humans create audio art.

This project could be expanded even farther with the proper access to WAV files. My end goal would be to use a similar method to let a computer bin songs into separate catgeories with no user influence. In other words, take 1,000,000 or more songs, extract the audio features and let a computer automatically sort the songs into a certain number of catergories (perhaps 200). 

It is my belief that this method could help build more robust recommendation systems, and also, perhaps influence future artists by opening their eyes to previously unseen music that is very similar to their own.
